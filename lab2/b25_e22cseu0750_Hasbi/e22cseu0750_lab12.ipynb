{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1: Visual Saliency Detection"
      ],
      "metadata": {
        "id": "9sS1ntwNvoIh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sw25YqiCvjDT"
      },
      "outputs": [],
      "source": [
        "pip install opencv-contrib-python\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saliency Detection on an Image"
      ],
      "metadata": {
        "id": "s0civ9vqv2S8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load the input image\n",
        "image = cv2.imread('input.jpg')\n",
        "if image is None:\n",
        "    raise FileNotFoundError(\"Image not found.\")\n",
        "\n",
        "# Initialize the saliency detector (Spectral Residual method)\n",
        "saliency = cv2.saliency.StaticSaliencySpectralResidual_create()\n",
        "\n",
        "# Compute the saliency map\n",
        "(success, saliency_map) = saliency.computeSaliency(image)\n",
        "if not success:\n",
        "    raise Exception(\"Saliency computation failed.\")\n",
        "\n",
        "# Convert the saliency map to a binary map\n",
        "saliency_map = (saliency_map * 255).astype(\"uint8\")\n",
        "_, binary_map = cv2.threshold(saliency_map, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
        "\n",
        "# Display the results\n",
        "cv2.imshow(\"Original Image\", image)\n",
        "cv2.imshow(\"Saliency Map\", saliency_map)\n",
        "cv2.imshow(\"Binary Map\", binary_map)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "FOKMEVObvv2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saliency Detection on a Video Stream"
      ],
      "metadata": {
        "id": "HbKj7yZTv7Tk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Open the video file or capture device\n",
        "cap = cv2.VideoCapture('input_video.mp4')  # Replace with 0 for webcam\n",
        "\n",
        "# Initialize the saliency detector\n",
        "saliency = cv2.saliency.MotionSaliencyBinWangApr2014_create()\n",
        "saliency.setImagesize(int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
        "saliency.init()\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Convert frame to grayscale as required by the saliency detector\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Compute the saliency map\n",
        "    success, saliency_map = saliency.computeSaliency(gray)\n",
        "    if not success:\n",
        "        continue\n",
        "\n",
        "    # Convert the saliency map to a displayable format\n",
        "    saliency_display = (saliency_map * 255).astype(\"uint8\")\n",
        "\n",
        "    # Display the results\n",
        "    cv2.imshow(\"Original Frame\", frame)\n",
        "    cv2.imshow(\"Saliency Map\", saliency_display)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "Xlw5ecjFv-IL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 2: Unsupervised Image Segmentation using K-Means Clustering"
      ],
      "metadata": {
        "id": "yMAPQ-rXwAe2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install opencv-python numpy\n"
      ],
      "metadata": {
        "id": "B2LeOHQ8wGe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load the image\n",
        "image = cv2.imread('landscape.jpg')\n",
        "if image is None:\n",
        "    raise FileNotFoundError(\"Image not found.\")\n",
        "Z = image.reshape((-1, 3))  # Reshape to a 2D array of pixels\n",
        "Z = np.float32(Z)  # Convert to float32\n",
        "\n",
        "# Define criteria and apply KMeans\n",
        "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
        "K = 4  # Number of clusters\n",
        "ret, label, center = cv2.kmeans(Z, K, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
        "\n",
        "# Convert back to uint8 and reshape to original image\n",
        "center = np.uint8(center)\n",
        "res = center[label.flatten()]\n",
        "segmented_image = res.reshape((image.shape))\n",
        "\n",
        "# Display the results\n",
        "cv2.imshow('Original Image', image)\n",
        "cv2.imshow('Segmented Image', segmented_image)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "VoegwTwrwLKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 3: Graph Cut Segmentation using GrabCut"
      ],
      "metadata": {
        "id": "LoUnvMKwwMob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install opencv-python\n"
      ],
      "metadata": {
        "id": "l23OoK6mwQeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load the image\n",
        "image = cv2.imread('input.jpg')\n",
        "if image is None:\n",
        "    raise FileNotFoundError(\"Image not found.\")\n",
        "mask = np.zeros(image.shape[:2], np.uint8)\n",
        "\n",
        "# Define the background and foreground models\n",
        "bgdModel = np.zeros((1, 65), np.float64)\n",
        "fgdModel = np.zeros((1, 65), np.float64)\n",
        "\n",
        "# Define the rectangle containing the foreground object\n",
        "rect = (50, 50, image.shape[1]-100, image.shape[0]-100)  # Adjust as needed\n",
        "\n",
        "# Apply GrabCut algorithm\n",
        "cv2.grabCut(image, mask, rect, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_RECT)\n",
        "\n",
        "# Create mask where sure and likely foreground are set to 1, others 0\n",
        "mask2 = np.where((mask==2)|(mask==0), 0, 1).astype('uint8')\n",
        "result = image * mask2[:, :, np.newaxis]\n",
        "\n",
        "# Display the results\n",
        "cv2.imshow('Original Image', image)\n",
        "cv2.imshow('Segmented Image', result)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "NUEjUuyUwTEX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}