# -*- coding: utf-8 -*-
"""computer vision_5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XszERyksa93aUz8GpPAc8x9tkPrApPE_
"""

from PIL import Image

# Load the image
image_path = "image.jpg"
image = Image.open(image_path)

# Lossy Compression (JPEG)
jpeg_path = "compressed_image.jpeg"
image.save(jpeg_path, "JPEG", quality=40)

# Lossless Compression (PNG)
png_path = "compressed_image.png"
image.save(png_path, "PNG", optimize=True)

print(f"JPEG image saved at: {jpeg_path}")
print(f"PNG image saved at: {png_path}")

from google.colab.patches import cv2_imshow
import cv2
import numpy as np
import matplotlib.pyplot as plt

# Load the image
image = cv2.imread('image.jpg')
gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

# Compute histogram for grayscale image
hist_gray = cv2.calcHist([gray_image], [0], None, [256], [0, 256])

# Compute histogram for each color channel
color_channels = ('b', 'g', 'r')
plt.figure(figsize=(12, 6))

for i, color in enumerate(color_channels):
    hist = cv2.calcHist([image], [i], None, [256], [0, 256])
    plt.plot(hist, color=color)

plt.title("Color Image Histogram")
plt.show()

# Display grayscale histogram
plt.figure(figsize=(8, 5))
plt.plot(hist_gray, color='black')
plt.title("Grayscale Image Histogram")
plt.show()

# Histogram Equalization
equalized_gray = cv2.equalizeHist(gray_image)

# Show original and enhanced images
cv2_imshow( gray_image)
cv2_imshow( equalized_gray)
cv2.waitKey(0)
cv2.destroyAllWindows()

# Load grayscale image
image = cv2.imread('image.jpg', 0)

# Compute Fourier Transform
dft = np.fft.fft2(image)
dft_shift = np.fft.fftshift(dft)
magnitude_spectrum = 20 * np.log(np.abs(dft_shift))

# Rotate Image by 45 Degrees
(h, w) = image.shape
center = (w // 2, h // 2)
rotation_matrix = cv2.getRotationMatrix2D(center, 45, 1.0)
rotated_image = cv2.warpAffine(image, rotation_matrix, (w, h))

# Compute FFT of rotated image
dft_rot = np.fft.fft2(rotated_image)
dft_shift_rot = np.fft.fftshift(dft_rot)
magnitude_spectrum_rot = 20 * np.log(np.abs(dft_shift_rot))

# Display results
plt.figure(figsize=(12, 6))
plt.subplot(131), plt.imshow(image, cmap='gray'), plt.title("Original Image")
plt.subplot(132), plt.imshow(magnitude_spectrum, cmap='gray'), plt.title("Fourier Transform")
plt.subplot(133), plt.imshow(magnitude_spectrum_rot, cmap='gray'), plt.title("Rotated Fourier Spectrum")
plt.show()

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.datasets import mnist, cifar10, cifar100
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc
import numpy as np
import seaborn as sns # Import seaborn for heatmap

# Function to plot accuracy and loss curves
def plot_history(history, dataset_name):
    plt.figure(figsize=(12, 4))

    # Accuracy Plot
    plt.subplot(1, 2, 1)
    plt.plot(history.history['accuracy'], label='Train Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.title(f'{dataset_name} - Model Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()

    # Loss Plot
    plt.subplot(1, 2, 2)
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.title(f'{dataset_name} - Model Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()

    plt.show()


# Function to evaluate the model and display performance metrics
def evaluate_model(model, x_test, y_test, dataset_name):
    y_pred = model.predict(x_test)
    y_pred_classes = y_pred.argmax(axis=1)
    y_true = y_test.argmax(axis=1)

    # Define class_labels for MNIST
    if dataset_name == "MNIST":
        class_labels = [str(i) for i in range(10)]
    elif dataset_name == "CIFAR-10":
        class_labels = [
            "Airplane", "Automobile", "Bird", "Cat", "Deer",
            "Dog", "Frog", "Horse", "Ship", "Truck"
        ]
    elif dataset_name == "CIFAR-100":
        class_labels = [
    "Apple", "Aquarium Fish", "Baby", "Bear", "Beaver", "Bed", "Bee", "Beetle", "Bicycle", "Bottle",
    "Bowl", "Boy", "Bridge", "Bus", "Butterfly", "Camel", "Can", "Castle", "Caterpillar", "Cattle",
    "Chair", "Chimpanzee", "Clock", "Cloud", "Cockroach", "Couch", "Crab", "Crocodile", "Cup", "Dinosaur",
    "Dolphin", "Elephant", "Flatfish", "Forest", "Fox", "Girl", "Hamster", "House", "Kangaroo", "Keyboard",
    "Lamp", "Lawn Mower", "Leopard", "Lion", "Lizard", "Lobster", "Man", "Maple Tree", "Motorcycle", "Mountain",
    "Mouse", "Mushroom", "Oak Tree", "Orange", "Orchid", "Otter", "Palm Tree", "Pear", "Pickup Truck", "Pine Tree",
    "Plain", "Plate", "Poppy", "Porcupine", "Possum", "Rabbit", "Raccoon", "Ray", "Road", "Rocket", "Rose",
    "Sea", "Seal", "Shark", "Shrew", "Skunk", "Skyscraper", "Snail", "Snake", "Spider", "Squirrel",
    "Streetcar", "Sunflower", "Sweet Pepper", "Table", "Tank", "Telephone", "Television", "Tiger", "Tractor", "Train",
    "Trout", "Tulip", "Turtle", "Wardrobe", "Whale", "Willow Tree", "Wolf", "Woman", "Worm"
]




    print(f"\nClassification Report for {dataset_name}:")
    print(classification_report(y_true, y_pred_classes, target_names=class_labels))

    # Compute Confusion Matrix
    cm = confusion_matrix(y_true, y_pred_classes)

    # Enhanced Confusion Matrix Visualization
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False,
                xticklabels=class_labels, yticklabels=class_labels,
                linewidths=1, linecolor='black')

    plt.xlabel("Predicted Labels", fontsize=14)
    plt.ylabel("True Labels", fontsize=14)
    plt.title(f"Confusion Matrix - {dataset_name}", fontsize=16)
    plt.xticks(rotation=45)
    plt.yticks(rotation=45)
    plt.show()

    # Compute ROC curve and AUC for one-vs-all (macro-averaged)
    fpr, tpr, _ = roc_curve(y_true, y_pred[:, 1], pos_label=1)
    roc_auc = auc(fpr, tpr)

    plt.figure()
    plt.plot(fpr, tpr, color='blue', label=f'ROC curve (AUC = {roc_auc:.2f})')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title(f'ROC Curve - {dataset_name}')
    plt.legend()
    plt.show()

# Load MNIST dataset
(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train.reshape(-1, 28, 28, 1) / 255.0, x_test.reshape(-1, 28, 28, 1) / 255.0
y_train, y_test = to_categorical(y_train, 10), to_categorical(y_test, 10)

# CNN Model for MNIST
mnist_model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    MaxPooling2D(pool_size=(2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(10, activation='softmax')
])

mnist_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
mnist_history = mnist_model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test), batch_size=128)

# Plot training history
plot_history(mnist_history, "MNIST")

# Evaluate model performance
evaluate_model(mnist_model, x_test, y_test, "MNIST",)

# Load CIFAR-10 dataset
(x_train, y_train), (x_test, y_test) = cifar10.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0
y_train, y_test = to_categorical(y_train, 10), to_categorical(y_test, 10)

# CNN Model for CIFAR-10
cifar10_model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),
    MaxPooling2D(pool_size=(2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),
    Flatten(),
    Dense(256, activation='relu'),
    Dropout(0.5),
    Dense(10, activation='softmax')
])

cifar10_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
cifar10_history = cifar10_model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test), batch_size=128)

# Plot training history
plot_history(cifar10_history, "CIFAR-10")

# Evaluate model performance
evaluate_model(cifar10_model, x_test, y_test, "CIFAR-10")

# Load CIFAR-100 dataset
(x_train, y_train), (x_test, y_test) = cifar100.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0
y_train, y_test = to_categorical(y_train, 100), to_categorical(y_test, 100)

# CNN Model for CIFAR-100
cifar100_model = Sequential([
    Conv2D(64, (3, 3), activation='relu', input_shape=(32, 32, 3)),
    MaxPooling2D(pool_size=(2, 2)),
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),
    Conv2D(256, (3, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),
    Flatten(),
    Dense(512, activation='relu'),
    Dropout(0.5),
    Dense(100, activation='softmax')
    ])

cifar100_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
cifar100_history = cifar100_model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test), batch_size=128)

# Plot training history
plot_history(cifar100_history, "CIFAR-100")

# Evaluate model performance
evaluate_model(cifar100_model, x_test, y_test, "CIFAR-100")