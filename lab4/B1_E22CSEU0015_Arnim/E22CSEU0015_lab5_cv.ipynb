{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3GsMFZY7c92"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import mnist, cifar10\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread('Picture.jpg')\n",
        "cv2.imwrite('compressed_i.jpg', image, [cv2.IMWRITE_JPEG_QUALITY, 50])\n",
        "cv2.imwrite('compressed_p.png', image, [cv2.IMWRITE_PNG_COMPRESSION, 9])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxabJogI7hRG",
        "outputId": "6e360419-301e-4225-8504-197ccd722683"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_mnist_model():\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\n",
        "        MaxPooling2D((2,2)),\n",
        "        Conv2D(64, (3,3), activation='relu'),\n",
        "        MaxPooling2D((2,2)),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "y_train, y_test = to_categorical(y_train, 10), to_categorical(y_test, 10)\n",
        "\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "model = build_mnist_model()\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=10, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYWmPxGd7nxf",
        "outputId": "0c29ec22-249a-45d1-a074-6c4e0c19400b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8495 - loss: 0.4746 - val_accuracy: 0.9809 - val_loss: 0.0608\n",
            "Epoch 2/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9720 - loss: 0.0934 - val_accuracy: 0.9887 - val_loss: 0.0396\n",
            "Epoch 3/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9809 - loss: 0.0641 - val_accuracy: 0.9881 - val_loss: 0.0458\n",
            "Epoch 4/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9856 - loss: 0.0466 - val_accuracy: 0.9901 - val_loss: 0.0349\n",
            "Epoch 5/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9881 - loss: 0.0380 - val_accuracy: 0.9905 - val_loss: 0.0359\n",
            "Epoch 6/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9908 - loss: 0.0296 - val_accuracy: 0.9909 - val_loss: 0.0367\n",
            "Epoch 7/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9897 - loss: 0.0320 - val_accuracy: 0.9908 - val_loss: 0.0336\n",
            "Epoch 8/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9920 - loss: 0.0247 - val_accuracy: 0.9898 - val_loss: 0.0404\n",
            "Epoch 9/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9929 - loss: 0.0230 - val_accuracy: 0.9919 - val_loss: 0.0399\n",
            "Epoch 10/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9931 - loss: 0.0218 - val_accuracy: 0.9919 - val_loss: 0.0355\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e680462d450>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_cifar10_model():\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)),\n",
        "        MaxPooling2D((2,2)),\n",
        "        Conv2D(64, (3,3), activation='relu'),\n",
        "        MaxPooling2D((2,2)),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "y_train, y_test = to_categorical(y_train, 10), to_categorical(y_test, 10)\n",
        "\n",
        "model = build_cifar10_model()\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=50, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rofzNrH27qAm",
        "outputId": "085116c1-2db9-4c75-d416-3e3ebd2f7a45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 0us/step\n",
            "Epoch 1/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.3073 - loss: 1.8684 - val_accuracy: 0.5138 - val_loss: 1.3965\n",
            "Epoch 2/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4903 - loss: 1.4189 - val_accuracy: 0.5921 - val_loss: 1.1732\n",
            "Epoch 3/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5569 - loss: 1.2475 - val_accuracy: 0.6130 - val_loss: 1.1158\n",
            "Epoch 4/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.5970 - loss: 1.1478 - val_accuracy: 0.5978 - val_loss: 1.1226\n",
            "Epoch 5/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.6179 - loss: 1.0833 - val_accuracy: 0.6587 - val_loss: 0.9936\n",
            "Epoch 6/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6401 - loss: 1.0253 - val_accuracy: 0.6610 - val_loss: 0.9829\n",
            "Epoch 7/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6566 - loss: 0.9817 - val_accuracy: 0.6538 - val_loss: 0.9850\n",
            "Epoch 8/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6690 - loss: 0.9427 - val_accuracy: 0.6786 - val_loss: 0.9354\n",
            "Epoch 9/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.6783 - loss: 0.9069 - val_accuracy: 0.6813 - val_loss: 0.9334\n",
            "Epoch 10/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6903 - loss: 0.8625 - val_accuracy: 0.6952 - val_loss: 0.9037\n",
            "Epoch 11/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7036 - loss: 0.8282 - val_accuracy: 0.6804 - val_loss: 0.9423\n",
            "Epoch 12/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7137 - loss: 0.8109 - val_accuracy: 0.6975 - val_loss: 0.9072\n",
            "Epoch 13/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7139 - loss: 0.7969 - val_accuracy: 0.6948 - val_loss: 0.8951\n",
            "Epoch 14/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.7290 - loss: 0.7537 - val_accuracy: 0.6943 - val_loss: 0.9059\n",
            "Epoch 15/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.7348 - loss: 0.7445 - val_accuracy: 0.7065 - val_loss: 0.8797\n",
            "Epoch 16/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7454 - loss: 0.7165 - val_accuracy: 0.6990 - val_loss: 0.9083\n",
            "Epoch 17/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7504 - loss: 0.6883 - val_accuracy: 0.7019 - val_loss: 0.9192\n",
            "Epoch 18/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7536 - loss: 0.6873 - val_accuracy: 0.7032 - val_loss: 0.9260\n",
            "Epoch 19/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7597 - loss: 0.6593 - val_accuracy: 0.6972 - val_loss: 0.9578\n",
            "Epoch 20/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7655 - loss: 0.6421 - val_accuracy: 0.7043 - val_loss: 0.9408\n",
            "Epoch 21/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.7708 - loss: 0.6342 - val_accuracy: 0.6941 - val_loss: 1.0083\n",
            "Epoch 22/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.7721 - loss: 0.6254 - val_accuracy: 0.7045 - val_loss: 0.9396\n",
            "Epoch 23/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7813 - loss: 0.5958 - val_accuracy: 0.7046 - val_loss: 0.9647\n",
            "Epoch 24/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7822 - loss: 0.5917 - val_accuracy: 0.7068 - val_loss: 0.9748\n",
            "Epoch 25/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7857 - loss: 0.5862 - val_accuracy: 0.7058 - val_loss: 0.9921\n",
            "Epoch 26/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7911 - loss: 0.5670 - val_accuracy: 0.7027 - val_loss: 1.0117\n",
            "Epoch 27/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7883 - loss: 0.5628 - val_accuracy: 0.6990 - val_loss: 1.0307\n",
            "Epoch 28/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.7956 - loss: 0.5509 - val_accuracy: 0.7039 - val_loss: 1.0355\n",
            "Epoch 29/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8013 - loss: 0.5372 - val_accuracy: 0.7022 - val_loss: 1.0097\n",
            "Epoch 30/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8049 - loss: 0.5257 - val_accuracy: 0.7086 - val_loss: 1.0702\n",
            "Epoch 31/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8065 - loss: 0.5108 - val_accuracy: 0.7027 - val_loss: 1.0734\n",
            "Epoch 32/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8076 - loss: 0.5114 - val_accuracy: 0.7020 - val_loss: 1.0494\n",
            "Epoch 33/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8140 - loss: 0.4934 - val_accuracy: 0.6981 - val_loss: 1.1039\n",
            "Epoch 34/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8109 - loss: 0.5076 - val_accuracy: 0.6931 - val_loss: 1.1094\n",
            "Epoch 35/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8117 - loss: 0.4951 - val_accuracy: 0.7016 - val_loss: 1.1185\n",
            "Epoch 36/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8136 - loss: 0.4913 - val_accuracy: 0.6947 - val_loss: 1.1676\n",
            "Epoch 37/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8175 - loss: 0.4797 - val_accuracy: 0.7060 - val_loss: 1.0972\n",
            "Epoch 38/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8167 - loss: 0.4865 - val_accuracy: 0.7015 - val_loss: 1.1602\n",
            "Epoch 39/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8240 - loss: 0.4706 - val_accuracy: 0.7038 - val_loss: 1.1453\n",
            "Epoch 40/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8282 - loss: 0.4583 - val_accuracy: 0.7008 - val_loss: 1.1696\n",
            "Epoch 41/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8250 - loss: 0.4571 - val_accuracy: 0.7039 - val_loss: 1.1615\n",
            "Epoch 42/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8272 - loss: 0.4434 - val_accuracy: 0.7106 - val_loss: 1.1921\n",
            "Epoch 43/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8316 - loss: 0.4379 - val_accuracy: 0.7022 - val_loss: 1.2364\n",
            "Epoch 44/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8336 - loss: 0.4346 - val_accuracy: 0.6983 - val_loss: 1.2484\n",
            "Epoch 45/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8320 - loss: 0.4354 - val_accuracy: 0.6930 - val_loss: 1.3183\n",
            "Epoch 46/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8360 - loss: 0.4248 - val_accuracy: 0.6981 - val_loss: 1.3102\n",
            "Epoch 47/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8389 - loss: 0.4194 - val_accuracy: 0.6925 - val_loss: 1.2793\n",
            "Epoch 48/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8402 - loss: 0.4182 - val_accuracy: 0.7018 - val_loss: 1.2667\n",
            "Epoch 49/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8445 - loss: 0.4065 - val_accuracy: 0.6940 - val_loss: 1.2862\n",
            "Epoch 50/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8415 - loss: 0.4125 - val_accuracy: 0.7032 - val_loss: 1.3034\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e68045acbd0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(x_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "print(classification_report(y_true, y_pred_classes))\n",
        "print(confusion_matrix(y_true, y_pred_classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7frspkHl7uxd",
        "outputId": "ef364b0a-d38f-4f44-c0fa-ca9f5f085276"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.72      0.73      1000\n",
            "           1       0.84      0.80      0.82      1000\n",
            "           2       0.62      0.57      0.59      1000\n",
            "           3       0.48      0.52      0.50      1000\n",
            "           4       0.66      0.62      0.64      1000\n",
            "           5       0.59      0.60      0.60      1000\n",
            "           6       0.75      0.78      0.76      1000\n",
            "           7       0.72      0.76      0.74      1000\n",
            "           8       0.81      0.79      0.80      1000\n",
            "           9       0.77      0.82      0.79      1000\n",
            "\n",
            "    accuracy                           0.70     10000\n",
            "   macro avg       0.70      0.70      0.70     10000\n",
            "weighted avg       0.70      0.70      0.70     10000\n",
            "\n",
            "[[723  16  56  27  19  10   8  20  77  44]\n",
            " [ 24 795   9  18   1   7  11   5  29 101]\n",
            " [ 68   6 566  80  82  85  58  38   9   8]\n",
            " [ 16   9  80 522  58 165  61  57  15  17]\n",
            " [ 22   4  75  78 616  37  73  79  13   3]\n",
            " [ 11   4  50 195  38 601  20  64   7  10]\n",
            " [  6   4  35  80  40  33 775  10   9   8]\n",
            " [ 14   1  23  47  67  60  11 760   1  16]\n",
            " [ 66  46   7  22   5  12   7   7 790  38]\n",
            " [ 32  64  13  19   3   7   6  16  21 819]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ejUyHgZn7whG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}