{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YiILbdzXQmJp"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "image_path = \"/content/image1.jpeg\"\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "_, mask = cv2.threshold(gray, 230, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "kernel = np.ones((5, 5), np.uint8)\n",
        "mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
        "mask = cv2.morphologyEx(mask, cv2.MORPH_DILATE, kernel)\n",
        "\n",
        "inpainted = cv2.inpaint(image, mask, inpaintRadius=5, flags=cv2.INPAINT_TELEA)\n",
        "\n",
        "cv2_imshow(image)       # Original Image\n",
        "cv2_imshow(mask)        # Refined Mask\n",
        "cv2_imshow(inpainted)   # Inpainted Image\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def create_blending_mask(img1, img2, overlap_width):\n",
        "    \"\"\"Creates a gradient mask for blending.\"\"\"\n",
        "    mask1 = np.zeros((max(img1.shape[0], img2.shape[0]), img1.shape[1]), dtype=np.float32)\n",
        "    mask2 = np.zeros((max(img1.shape[0], img2.shape[0]), img2.shape[1]), dtype=np.float32)\n",
        "\n",
        "    mask1[:, :-overlap_width] = 1.0\n",
        "    mask1[:, -overlap_width:] = np.linspace(1.0, 0.0, overlap_width)\n",
        "\n",
        "    mask2[:, :overlap_width] = np.linspace(0.0, 1.0, overlap_width)\n",
        "    mask2[:, overlap_width:] = 1.0\n",
        "\n",
        "    return mask1, mask2\n",
        "\n",
        "img1 = cv2.imread(\"LeftImage.png\")\n",
        "img2 = cv2.imread(\"RightImage.png\")\n",
        "\n",
        "if img1 is None or img2 is None:\n",
        "    raise FileNotFoundError(\"Could not load one or both of the images.\")\n",
        "\n",
        "gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
        "gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "sift = cv2.SIFT_create()\n",
        "kp1, des1 = sift.detectAndCompute(gray1, None)\n",
        "kp2, des2 = sift.detectAndCompute(gray2, None)\n",
        "\n",
        "FLANN_INDEX_KDTREE = 1\n",
        "index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
        "search_params = dict(checks=100)\n",
        "\n",
        "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
        "matches = flann.knnMatch(des1, des2, k=2)\n",
        "\n",
        "good_matches = []\n",
        "for m, n in matches:\n",
        "    if m.distance < 0.6 * n.distance:\n",
        "        good_matches.append(m)\n",
        "\n",
        "if len(good_matches) < 10:\n",
        "    raise Exception(\"Not enough good matches found. Panorama stitching might fail.\")\n",
        "\n",
        "src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
        "dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
        "\n",
        "H, mask = cv2.findHomography(dst_pts, src_pts, cv2.RANSAC, 5.0, confidence=0.99)\n",
        "\n",
        "if H is None:\n",
        "    raise Exception(\"Homography could not be computed. Check feature matching.\")\n",
        "\n",
        "height = max(img1.shape[0], img2.shape[0])\n",
        "width = img1.shape[1] + img2.shape[1]\n",
        "warped_img2 = cv2.warpPerspective(img2, H, (width, height))\n",
        "stitched_img = np.zeros((height, width, 3), dtype=np.uint8)\n",
        "stitched_img[:img1.shape[0], :img1.shape[1]] = img1\n",
        "\n",
        "overlap_width = 50\n",
        "blend_start = img1.shape[1] - overlap_width\n",
        "blend_end = img1.shape[1]\n",
        "\n",
        "blend_mask = np.linspace(1, 0, overlap_width).reshape(1, overlap_width, 1)\n",
        "\n",
        "roi1 = stitched_img[:img1.shape[0], blend_start:blend_end].astype(np.float32)\n",
        "roi2 = warped_img2[:img1.shape[0], blend_start:blend_end].astype(np.float32)\n",
        "\n",
        "blended_roi = (roi1 * blend_mask + roi2 * (1 - blend_mask)).astype(np.uint8)\n",
        "\n",
        "stitched_img[:img1.shape[0], blend_start:blend_end] = blended_roi\n",
        "\n",
        "stitched_img[:img2.shape[0], img1.shape[1]:] = warped_img2[:img2.shape[0], img1.shape[1]:]\n",
        "\n",
        "gray_stitched = cv2.cvtColor(stitched_img, cv2.COLOR_BGR2GRAY)\n",
        "_, thresh_stitched = cv2.threshold(gray_stitched, 1, 255, cv2.THRESH_BINARY)\n",
        "contours_stitched, _ = cv2.findContours(thresh_stitched, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "if contours_stitched:\n",
        "    x, y, w, h = cv2.boundingRect(contours_stitched[0])\n",
        "    final_result = stitched_img[y:y+h, x:x+w]\n",
        "else:\n",
        "    final_result = stitched_img\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.imshow(cv2.cvtColor(final_result, cv2.COLOR_BGR2RGB))\n",
        "plt.title(\"Improved Panorama Stitching with Direct Gradient Blend\")\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "\"\"\"<h1>Task 2</h1>\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "\n",
        "\n",
        "(x_train, _), (x_test, _) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype(\"float32\") / 255.\n",
        "x_test = x_test.astype(\"float32\") / 255.\n",
        "\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "\n",
        "def add_noise(images, noise_factor=0.2):\n",
        "    noisy = images + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=images.shape)\n",
        "    noisy = np.clip(noisy, 0., 1.)\n",
        "    return noisy\n",
        "\n",
        "noisy_train = add_noise(x_train)\n",
        "noisy_test = add_noise(x_test)\n",
        "\n",
        "def build_autoencoder():\n",
        "    input_img = layers.Input(shape=(28, 28, 1))\n",
        "\n",
        "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(encoded)\n",
        "    x = layers.UpSampling2D((2, 2))(x)\n",
        "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.UpSampling2D((2, 2))(x)\n",
        "    decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "    return models.Model(input_img, decoded)\n",
        "\n",
        "autoencoder = build_autoencoder()\n",
        "autoencoder.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "history = autoencoder.fit(noisy_train, x_train,\n",
        "                          epochs=100,\n",
        "                          batch_size=128,\n",
        "                          shuffle=True,\n",
        "                          validation_data=(noisy_test, x_test))\n",
        "\n",
        "preds = autoencoder.predict(noisy_test)\n",
        "\n",
        "scores = [psnr(x_test[i], preds[i], data_range=1.0) for i in range(100)]\n",
        "print(\"Average PSNR on 100 samples:\", np.mean(scores))\n",
        "\n",
        "n = 10\n",
        "plt.figure(figsize=(20, 6))\n",
        "for i in range(n):\n",
        "\n",
        "    ax = plt.subplot(3, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28), cmap=\"gray\")\n",
        "    plt.title(\"Original\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    ax = plt.subplot(3, n, i + 1 + n)\n",
        "    plt.imshow(noisy_test[i].reshape(28, 28), cmap=\"gray\")\n",
        "    plt.title(\"Noisy\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    ax = plt.subplot(3, n, i + 1 + 2 * n)\n",
        "    plt.imshow(preds[i].reshape(28, 28), cmap=\"gray\")\n",
        "    plt.title(\"Restored\")\n",
        "    plt.axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(history.history['loss'], label='train_loss')\n",
        "plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device= torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5]),\n",
        "    transforms.Lambda(lambda x: x.to(device))\n",
        "\n",
        "])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root='CIFAR/', train=True, transform=transforms, download=True)\n",
        "test_dataset = datasets.CIFAR10(root='CIFAR/', train=False, transform=transforms, download=True)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "class ConvAutoEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3, stride=3, padding=1), nn.ReLU(True),\n",
        "            # for input shape (2,1,28,28)\n",
        "            # output is (2,32,10,10)\n",
        "            nn.MaxPool2d(2, stride=2),\n",
        "            # output is (2,32,5,5)\n",
        "            nn.Conv2d(32, 64, 3, stride=2, padding=1), nn.ReLU(True),\n",
        "            #outpur is (2,64,3,3)\n",
        "            nn.MaxPool2d(2, stride=1)\n",
        "            #output is (2,64,2,2)\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(64, 32, 3, stride=2), nn.ReLU(True),\n",
        "            #output is (2,32,5,5)\n",
        "            nn.ConvTranspose2d(32, 16, 5, stride=3, padding=1), nn.ReLU(True),\n",
        "            # output is (2,16,15,15)\n",
        "            nn.ConvTranspose2d(16, 1, 2, stride=2, padding=1), nn.Tanh()\n",
        "            # output is (2,1,28,28)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        print(x.shape)\n",
        "        return x\n",
        "\n",
        "class AEModel(nn.Module):\n",
        "    def __init__(self, cin, cout, stride=1, groups=1):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(cin, 64, 3, stride=3, padding=1), nn.ReLU(True),\n",
        "            nn.MaxPool2d(2, stride=2),\n",
        "            nn.Conv2d(64, cout, 3, stride=2, padding=1), nn.ReLU(True),\n",
        "            nn.MaxPool2d(2, stride=1)\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(cout, 64, 3, stride=2), nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(64, 32, 5, stride=3, padding=1), nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(32, cin, 4, stride=2), nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "model_test = AEModel(3,128)\n",
        "model_test(torch.rand(2,3,32,32)).shape\n",
        "\n",
        "def train (model,train_loader,loss,opt,device):\n",
        "    model.train()\n",
        "    loss_history=[]\n",
        "    for true_image,_ in train_loader:\n",
        "        opt.zero_grad()\n",
        "        true_image=true_image.to(device)\n",
        "        generated_image=model(true_image)\n",
        "        lss=loss(generated_image,true_image)\n",
        "        lss.backward()\n",
        "        opt.step()\n",
        "        loss_history.append(lss.item())\n",
        "    return np.mean(loss_history)\n",
        "\n",
        "def val (model,test_loader,loss,device):\n",
        "    model.eval()\n",
        "    loss_history=[]\n",
        "    with torch.no_grad():\n",
        "        for val_image,_ in test_loader:\n",
        "            true_image=val_image.to(device)\n",
        "            generated_image=model(true_image)\n",
        "            lss=loss(generated_image,true_image)\n",
        "            loss_history.append(lss.item())\n",
        "    return np.mean(loss_history)\n",
        "\n",
        "model = AEModel(3,128).to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "\n",
        "num_epochs = 20\n",
        "trainl=[]\n",
        "testl=[]\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train(model,train_loader, criterion, optimizer,device)\n",
        "    loss = val( model,test_loader, criterion,device)\n",
        "    trainl.append(train_loss)\n",
        "    testl.append(loss)\n",
        "    print(f'epoic {epoch+1}   ||  training loss is {train_loss} ||   val loss is {loss}')\n",
        "\n",
        "plt.figure()\n",
        "epochs=[epoch for epoch in range (num_epochs)]\n",
        "plt.plot(epochs, trainl, 'b', color='red',label='Training loss')\n",
        "plt.plot(epochs, testl, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "def show(img, ax=None, title=None):\n",
        "    \"\"\"Utility function to display an image\"\"\"\n",
        "    if ax is None:\n",
        "        ax = plt.gca()\n",
        "    img = img.cpu().detach().numpy()\n",
        "    if img.shape[0] == 1:  # Grayscale image\n",
        "        img = img[0]\n",
        "        ax.imshow(img, cmap='gray')\n",
        "    else:  # RGB image\n",
        "        img = img.transpose((1, 2, 0))  # Convert to HWC format\n",
        "        ax.imshow(img)\n",
        "    if title is not None:\n",
        "        ax.set_title(title)\n",
        "    ax.axis('off')\n",
        "\n",
        "for _ in range(10):\n",
        "    ix = np.random.randint(len(test_dataset))\n",
        "    im, _ = test_dataset[ix]\n",
        "    _im = model(im.unsqueeze(0).to(device))[0]\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(6, 3))\n",
        "    show(im, ax=ax[0], title='Input')\n",
        "    show(_im, ax=ax[1], title='Prediction')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,)),\n",
        "    transforms.Lambda(lambda x: x.to(device))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='MNIST/', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.MNIST(root='MNIST/', train=False, transform=transform, download=True)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "class ConvAutoEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3, stride=1, padding=1), nn.ReLU(True),  # Keep output 28x28\n",
        "            nn.MaxPool2d(2, stride=2),  # Output size: (batch, 32, 14, 14)\n",
        "            nn.Conv2d(32, 64, 3, stride=1, padding=1), nn.ReLU(True),  # Output size: (batch, 64, 14, 14)\n",
        "            nn.MaxPool2d(2, stride=2)  # Output size: (batch, 64, 7, 7)\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1), nn.ReLU(True),  # Output size: (batch, 32, 14, 14)\n",
        "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1), nn.ReLU(True),  # Output size: (batch, 16, 28, 28)\n",
        "            nn.ConvTranspose2d(16, 1, 3, stride=1, padding=1), nn.Tanh()  # Output size: (batch, 1, 28, 28)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "model = ConvAutoEncoder().to(device)  # Use ConvAutoEncoder for MNIST (grayscale)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "\n",
        "def train(model, train_loader, loss, opt, device):\n",
        "    model.train()\n",
        "    loss_history = []\n",
        "    for true_image, _ in train_loader:\n",
        "        opt.zero_grad()\n",
        "        true_image = true_image.to(device)\n",
        "        generated_image = model(true_image)\n",
        "        lss = loss(generated_image, true_image)\n",
        "        lss.backward()\n",
        "        opt.step()\n",
        "        loss_history.append(lss.item())\n",
        "    return np.mean(loss_history)\n",
        "\n",
        "def val(model, test_loader, loss, device):\n",
        "    model.eval()\n",
        "    loss_history = []\n",
        "    with torch.no_grad():\n",
        "        for val_image, _ in test_loader:\n",
        "            true_image = val_image.to(device)\n",
        "            generated_image = model(true_image)\n",
        "            lss = loss(generated_image, true_image)\n",
        "            loss_history.append(lss.item())\n",
        "    return np.mean(loss_history)\n",
        "\n",
        "num_epochs = 20\n",
        "trainl = []\n",
        "testl = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train(model, train_loader, criterion, optimizer, device)\n",
        "    loss = val(model, test_loader, criterion, device)\n",
        "    trainl.append(train_loss)\n",
        "    testl.append(loss)\n",
        "    print(f'Epoch {epoch+1}   ||  Training loss: {train_loss} ||   Validation loss: {loss}')\n",
        "\n",
        "plt.figure()\n",
        "epochs = [epoch for epoch in range(num_epochs)]\n",
        "plt.plot(epochs, trainl, 'b', color='red', label='Training loss')\n",
        "plt.plot(epochs, testl, 'b', label='Validation loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "def show(img, ax=None, title=None):\n",
        "    \"\"\"Utility function to display an image\"\"\"\n",
        "    if ax is None:\n",
        "        ax = plt.gca()\n",
        "    img = img.cpu().detach().numpy()\n",
        "    if img.shape[0] == 1:  # Grayscale image\n",
        "        img = img[0]\n",
        "        ax.imshow(img, cmap='gray')\n",
        "    else:  # RGB image\n",
        "        img = img.transpose((1, 2, 0))  # Convert to HWC format\n",
        "        ax.imshow(img)\n",
        "    if title is not None:\n",
        "        ax.set_title(title)\n",
        "    ax.axis('off')\n",
        "\n",
        "for _ in range(10):\n",
        "    ix = np.random.randint(len(test_dataset))\n",
        "    im, _ = test_dataset[ix]\n",
        "    _im = model(im.unsqueeze(0).to(device))[0]\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(6, 3))\n",
        "    show(im, ax=ax[0], title='Input')\n",
        "    show(_im, ax=ax[1], title='Prediction')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "from __future__ import print_function\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cudnn.benchmark = True\n",
        "\n",
        "manualSeed = random.randint(1, 10000)\n",
        "print(\"Random Seed: \", manualSeed)\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)\n",
        "\n",
        "os.makedirs(\"output\", exist_ok=True)\n",
        "os.makedirs(\"weights\", exist_ok=True)\n",
        "\n",
        "dataset = dset.CIFAR10(\n",
        "    root=\"./data\", download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.Resize(64),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    ])\n",
        ")\n",
        "\n",
        "nc = 3\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=128, shuffle=True, num_workers=2)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "ngpu = 1\n",
        "nz = 100\n",
        "ngf = 64\n",
        "ndf = 64\n",
        "\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        m.weight.data.normal_(0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(1.0, 0.02)\n",
        "        m.bias.data.fill_(0)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Generator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n",
        "\n",
        "netG = Generator(ngpu).to(device)\n",
        "netG.apply(weights_init)\n",
        "print(netG)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input).view(-1, 1).squeeze(1)\n",
        "\n",
        "netD = Discriminator(ngpu).to(device)\n",
        "netD.apply(weights_init)\n",
        "print(netD)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "fixed_noise = torch.randn(128, nz, 1, 1, device=device)\n",
        "real_label = 1\n",
        "fake_label = 0\n",
        "niter = 25\n",
        "\n",
        "for epoch in range(niter):\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "        netD.zero_grad()\n",
        "        real_cpu = data[0].to(device)\n",
        "        batch_size = real_cpu.size(0)\n",
        "\n",
        "        label = torch.full((batch_size,), real_label, device=device, dtype=torch.float)\n",
        "\n",
        "        output = netD(real_cpu)\n",
        "        errD_real = criterion(output, label)\n",
        "        errD_real.backward()\n",
        "        D_x = output.mean().item()\n",
        "\n",
        "        noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
        "        fake = netG(noise)\n",
        "        label.fill_(fake_label)\n",
        "        output = netD(fake.detach())\n",
        "        errD_fake = criterion(output, label)\n",
        "        errD_fake.backward()\n",
        "        D_G_z1 = output.mean().item()\n",
        "        errD = errD_real + errD_fake\n",
        "        optimizerD.step()\n",
        "\n",
        "        netG.zero_grad()\n",
        "        label.fill_(real_label)\n",
        "        output = netD(fake)\n",
        "        errG = criterion(output, label)\n",
        "        errG.backward()\n",
        "        D_G_z2 = output.mean().item()\n",
        "        optimizerG.step()\n",
        "\n",
        "\n",
        "        if i % 50 == 0:\n",
        "            print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f' %\n",
        "                  (epoch, niter, i, len(dataloader), errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            vutils.save_image(real_cpu, 'output/real_samples.png', normalize=True)\n",
        "            fake = netG(fixed_noise)\n",
        "            vutils.save_image(fake.detach(), f'output/fake_samples_epoch_{epoch:03d}.png', normalize=True)\n",
        "\n",
        "    torch.save(netG.state_dict(), f'weights/netG_epoch_{epoch}.pth')\n",
        "    torch.save(netD.state_dict(), f'weights/netD_epoch_{epoch}.pth')\n",
        "\n",
        "import os\n",
        "from IPython.display import Image, display\n",
        "\n",
        "output_path = \"/content/output\"\n",
        "\n",
        "image_files = sorted([f for f in os.listdir(output_path) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
        "\n",
        "for img_file in image_files:\n",
        "    display(Image(filename=os.path.join(output_path, img_file)))\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()\n",
        "train_images = (train_images.astype(\"float32\") - 127.5) / 127.5\n",
        "train_images = np.expand_dims(train_images, axis=-1)\n",
        "BUFFER_SIZE = 60000\n",
        "BATCH_SIZE = 256\n",
        "dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "\n",
        "def build_generator():\n",
        "    model = tf.keras.Sequential([\n",
        "        layers.Dense(7*7*256, use_bias=False, input_shape=(100,)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.LeakyReLU(),\n",
        "        layers.Reshape((7, 7, 256)),\n",
        "        layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.LeakyReLU(),\n",
        "        layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.LeakyReLU(),\n",
        "        layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def build_discriminator():\n",
        "    model = tf.keras.Sequential([\n",
        "        layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[28, 28, 1]),\n",
        "        layers.LeakyReLU(),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'),\n",
        "        layers.LeakyReLU(),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    return tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.zeros_like(fake_output), fake_output)\n",
        "    return real_loss + fake_loss\n",
        "\n",
        "generator = build_generator()\n",
        "discriminator = build_discriminator()\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([BATCH_SIZE, 100])\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_images = generator(noise, training=True)\n",
        "        real_output = discriminator(images, training=True)\n",
        "        fake_output = discriminator(generated_images, training=True)\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "def generate_and_show_images(epoch, noise_dim=100):\n",
        "    noise = tf.random.normal([16, noise_dim])\n",
        "    generated_images = generator(noise, training=False)\n",
        "    fig = plt.figure(figsize=(4, 4))\n",
        "    for i in range(generated_images.shape[0]):\n",
        "        plt.subplot(4, 4, i + 1)\n",
        "        plt.imshow(generated_images[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "        plt.axis('off')\n",
        "    plt.suptitle(f\"Epoch {epoch}\")\n",
        "    plt.show()\n",
        "\n",
        "def train(dataset, epochs, display_interval=10):\n",
        "    for epoch in range(epochs):\n",
        "        for image_batch in dataset:\n",
        "            train_step(image_batch)\n",
        "        print(f\"Epoch {epoch+1} completed\")\n",
        "        if (epoch) % display_interval == 0:\n",
        "            generate_and_show_images(epoch + 1)\n",
        "\n",
        "EPOCHS = 100\n",
        "train(dataset, EPOCHS, display_interval=1)\n",
        "\n",
        "generate_and_show_images('final')\n",
        "\n",
        "!kaggle competitions download -c dog-breed-identification\n",
        "!unzip dog-breed-identification.zip -d dog_breeds\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle competitions download -c dog-breed-identification\n",
        "!unzip dog-breed-identification.zip -d dog_breeds\n",
        "\n",
        "\"\"\"<h1>V2</h1>\"\"\"\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "labels_df = pd.read_csv('dog_breeds/labels.csv')\n",
        "\n",
        "image_dir = 'dog_breeds/train/'\n",
        "image_size = 224\n",
        "batch_size = 32\n",
        "\n",
        "labels_df['id'] = labels_df['id'].apply(lambda x: x + '.jpg')\n",
        "\n",
        "train_df, val_df = train_test_split(labels_df, test_size=0.2, stratify=labels_df['breed'])\n",
        "\n",
        "datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "train_gen = datagen.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    directory=image_dir,\n",
        "    x_col='id',\n",
        "    y_col='breed',\n",
        "    target_size=(image_size, image_size),\n",
        "    class_mode='categorical',\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "val_gen = datagen.flow_from_dataframe(\n",
        "    dataframe=val_df,\n",
        "    directory=image_dir,\n",
        "    x_col='id',\n",
        "    y_col='breed',\n",
        "    target_size=(image_size, image_size),\n",
        "    class_mode='categorical',\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
        "\n",
        "base_model.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "\n",
        "num_classes = len(train_gen.class_indices)\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=5\n",
        ")\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "if not hasattr(np, 'Inf'):\n",
        "    np.Inf = np.inf\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='Train Acc')\n",
        "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
        "plt.title('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import random\n",
        "\n",
        "sample_images = train_df.sample(9)\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "\n",
        "for i, row in enumerate(sample_images.itertuples(), 1):\n",
        "    img_path = os.path.join(image_dir, row.id)\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    plt.subplot(3, 3, i)\n",
        "    plt.imshow(img)\n",
        "    plt.title(row.breed)\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "test_dir = 'dog_breeds/test/'\n",
        "\n",
        "test_files = os.listdir(test_dir)\n",
        "test_df = pd.DataFrame({'id': test_files})\n",
        "test_df['id'] = test_df['id'].apply(lambda x: x)\n",
        "\n",
        "test_gen = datagen.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    directory=test_dir,\n",
        "    x_col='id',\n",
        "    y_col=None,\n",
        "    class_mode=None,\n",
        "    target_size=(image_size, image_size),\n",
        "    batch_size=1,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "preds = model.predict(test_gen)\n",
        "pred_labels = np.argmax(preds, axis=1)\n",
        "\n",
        "\"\"\"<h1>V1</h1>\"\"\"\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNet\n",
        "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "import cv2\n",
        "\n",
        "labels_df = pd.read_csv('dog_breeds/labels.csv')\n",
        "\n",
        "image_dir = 'dog_breeds/train/'\n",
        "image_size = 224\n",
        "batch_size = 32\n",
        "\n",
        "labels_df['id'] = labels_df['id'].apply(lambda x: x + '.jpg')\n",
        "\n",
        "train_df, val_df = train_test_split(labels_df, test_size=0.2, stratify=labels_df['breed'])\n",
        "\n",
        "datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "train_gen = datagen.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    directory=image_dir,\n",
        "    x_col='id',\n",
        "    y_col='breed',\n",
        "    target_size=(image_size, image_size),\n",
        "    class_mode='categorical',\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "val_gen = datagen.flow_from_dataframe(\n",
        "    dataframe=val_df,\n",
        "    directory=image_dir,\n",
        "    x_col='id',\n",
        "    y_col='breed',\n",
        "    target_size=(image_size, image_size),\n",
        "    class_mode='categorical',\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
        "\n",
        "base_model.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "\n",
        "num_classes = len(train_gen.class_indices)\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=5\n",
        ")\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='Train Acc')\n",
        "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
        "plt.title('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "sample_images = train_df.sample(9)\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "\n",
        "for i, row in enumerate(sample_images.itertuples(), 1):\n",
        "    img_path = os.path.join(image_dir, row.id)\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    plt.subplot(3, 3, i)\n",
        "    plt.imshow(img)\n",
        "    plt.title(row.breed)\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "test_dir = 'dog_breeds/test/'\n",
        "test_files = os.listdir(test_dir)\n",
        "test_df = pd.DataFrame({'id': test_files})\n",
        "test_df['id'] = test_df['id'].apply(lambda x: x)\n",
        "\n",
        "test_gen = datagen.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    directory=test_dir,\n",
        "    x_col='id',\n",
        "    y_col=None,\n",
        "    class_mode=None,\n",
        "    target_size=(image_size, image_size),\n",
        "    batch_size=1,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "preds = model.predict(test_gen)\n",
        "\n",
        "pred_labels = np.argmax(preds, axis=1)\n",
        "\n",
        "\"\"\"<h1>V3</h1>\"\"\"\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV3Large  # MobileNetV3 Large variant\n",
        "from tensorflow.keras.applications.mobilenet_v3 import preprocess_input\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "import cv2\n",
        "\n",
        "labels_df = pd.read_csv('dog_breeds/labels.csv')\n",
        "\n",
        "image_dir = 'dog_breeds/train/'\n",
        "image_size = 224\n",
        "batch_size = 32\n",
        "\n",
        "labels_df['id'] = labels_df['id'].apply(lambda x: x + '.jpg')\n",
        "\n",
        "train_df, val_df = train_test_split(labels_df, test_size=0.2, stratify=labels_df['breed'])\n",
        "\n",
        "datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "train_gen = datagen.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    directory=image_dir,\n",
        "    x_col='id',\n",
        "    y_col='breed',\n",
        "    target_size=(image_size, image_size),\n",
        "    class_mode='categorical',\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "val_gen = datagen.flow_from_dataframe(\n",
        "    dataframe=val_df,\n",
        "    directory=image_dir,\n",
        "    x_col='id',\n",
        "    y_col='breed',\n",
        "    target_size=(image_size, image_size),\n",
        "    class_mode='categorical',\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "base_model = MobileNetV3Large(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
        "\n",
        "base_model.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "\n",
        "num_classes = len(train_gen.class_indices)\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=5\n",
        ")\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='Train Acc')\n",
        "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
        "plt.title('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "sample_images = train_df.sample(9)\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "\n",
        "for i, row in enumerate(sample_images.itertuples(), 1):\n",
        "    img_path = os.path.join(image_dir, row.id)\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    plt.subplot(3, 3, i)\n",
        "    plt.imshow(img)\n",
        "    plt.title(row.breed)\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "test_dir = 'dog_breeds/test/'\n",
        "test_files = os.listdir(test_dir)\n",
        "test_df = pd.DataFrame({'id': test_files})\n",
        "test_df['id'] = test_df['id'].apply(lambda x: x)\n",
        "\n",
        "test_gen = datagen.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    directory=test_dir,\n",
        "    x_col='id',\n",
        "    y_col=None,\n",
        "    class_mode=None,\n",
        "    target_size=(image_size, image_size),\n",
        "    batch_size=1,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "preds = model.predict(test_gen)\n",
        "\n",
        "pred_labels = np.argmax(preds, axis=1)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, UpSampling2D, Input, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "dataset, info = tfds.load('oxford_iiit_pet', with_info=True)\n",
        "\n",
        "def normalize(input_image, input_mask):\n",
        "    input_image = tf.cast(input_image, tf.float32) / 255.0\n",
        "    input_mask = tf.cast(input_mask, tf.uint8)\n",
        "    input_mask -= 1\n",
        "    input_mask = tf.where(input_mask == 1, 1, 0)\n",
        "    return input_image, input_mask\n",
        "\n",
        "def load_image(datapoint):\n",
        "    input_image = tf.image.resize(datapoint['image'], (128, 128))\n",
        "    input_mask = tf.image.resize(datapoint['segmentation_mask'], (128, 128))\n",
        "    input_image, input_mask = normalize(input_image, input_mask)\n",
        "    return input_image, input_mask\n",
        "\n",
        "train = dataset['train'].map(load_image)\n",
        "test = dataset['test'].map(load_image)\n",
        "\n",
        "train_dataset = train.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "def unet_model(input_size=(128, 128, 3)):\n",
        "    inputs = Input(input_size)\n",
        "\n",
        "    # Encoder\n",
        "    c1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
        "    c1 = Conv2D(64, 3, activation='relu', padding='same')(c1)\n",
        "    p1 = MaxPooling2D()(c1)\n",
        "\n",
        "    c2 = Conv2D(128, 3, activation='relu', padding='same')(p1)\n",
        "    c2 = Conv2D(128, 3, activation='relu', padding='same')(c2)\n",
        "    p2 = MaxPooling2D()(c2)\n",
        "\n",
        "    # Bottleneck\n",
        "    c3 = Conv2D(256, 3, activation='relu', padding='same')(p2)\n",
        "    c3 = Conv2D(256, 3, activation='relu', padding='same')(c3)\n",
        "\n",
        "    # Decoder\n",
        "    u1 = UpSampling2D()(c3)\n",
        "    u1 = concatenate([u1, c2])\n",
        "    c4 = Conv2D(128, 3, activation='relu', padding='same')(u1)\n",
        "    c4 = Conv2D(128, 3, activation='relu', padding='same')(c4)\n",
        "\n",
        "    u2 = UpSampling2D()(c4)\n",
        "    u2 = concatenate([u2, c1])\n",
        "    c5 = Conv2D(64, 3, activation='relu', padding='same')(u2)\n",
        "    c5 = Conv2D(64, 3, activation='relu', padding='same')(c5)\n",
        "\n",
        "    outputs = Conv2D(1, 1, activation='sigmoid')(c5)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "model = unet_model()\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_dataset, validation_data=test_dataset, epochs=10)\n",
        "\n",
        "def iou_metric(y_true, y_pred):\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    y_pred = tf.cast(y_pred > 0.5, tf.float32)\n",
        "    intersection = tf.reduce_sum(y_true * y_pred)\n",
        "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection\n",
        "    return intersection / (union + 1e-7)\n",
        "\n",
        "def dice_coefficient(y_true, y_pred):\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    y_pred = tf.cast(y_pred > 0.5, tf.float32)\n",
        "    intersection = tf.reduce_sum(y_true * y_pred)\n",
        "    return (2. * intersection) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + 1e-7)\n",
        "\n",
        "for images, masks in test_dataset.take(1):\n",
        "    preds = model.predict(images)\n",
        "    iou = iou_metric(masks, preds).numpy()\n",
        "    dice = dice_coefficient(masks, preds).numpy()\n",
        "\n",
        "print(f\"IoU Score: {iou:.4f}\")\n",
        "print(f\"Dice Coefficient: {dice:.4f}\")\n",
        "\n",
        "import numpy as np\n",
        "np.Inf = np.inf\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def display_sample(image, mask, pred_mask):\n",
        "\n",
        "    if np.any(np.isinf(image)) or np.any(np.isinf(mask)) or np.any(np.isinf(pred_mask)):\n",
        "        print(\"Detected np.Inf, replacing with np.inf\")\n",
        "\n",
        "    plt.figure(figsize=(10, 3))\n",
        "    titles = [\"Input Image\", \"True Mask\", \"Predicted Mask\"]\n",
        "    images = [image, mask, pred_mask]\n",
        "\n",
        "    for i in range(3):\n",
        "        plt.subplot(1, 3, i + 1)\n",
        "        plt.title(titles[i])\n",
        "        plt.imshow(tf.keras.utils.array_to_img(images[i]))\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "for image, mask in test_dataset.take(1):\n",
        "    pred_mask = model.predict(image)\n",
        "    display_sample(image[0], mask[0], pred_mask[0])\n"
      ]
    }
  ]
}
